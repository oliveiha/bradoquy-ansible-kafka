---
### Validates that custom log4j appenders are present on each component.
### Validates that Service Description has been overridden.
### Validates that SASL Plaintext protocol is set across components.
### Validates that Connectors are present on Kafka Connect.

- name: Verify - zookeeper
  hosts: zookeeper
  gather_facts: false
  tasks:
    - import_role:
        name: confluent.test
        tasks_from: check_property.yml
      vars:
        file_path: /etc/kafka/zookeeper.properties
        property: dataLogDir
        expected_value: /opt/zookeeper

    - import_role:
        name: confluent.test
        tasks_from: check_ownership.yml
      vars:
        file_name: log.1
        custom_path: /opt/zookeeper/version-2/
        group: confluent
        user: cp-kafka

    - name: Check Updated Service Description
      shell: systemctl status confluent-zookeeper
      register: systemctl_status
      failed_when: "'Custom Zookeeper description' not in systemctl_status.stdout_lines[0]"
      changed_when: false

    - import_role:
        name: confluent.test
        tasks_from: check_property.yml
      vars:
        file_path: /etc/kafka/zookeeper-log4j.properties
        property: log4j.rootLogger
        expected_value: "INFO, zkAppender"

- name: Verify - kafka_broker
  hosts: kafka_broker
  gather_facts: false
  tasks:
    - import_role:
        name: confluent.test
        tasks_from: check_property.yml
      vars:
        file_path: /etc/kafka/server.properties
        property: listener.name.internal.sasl.enabled.mechanisms
        expected_value: PLAIN

    - import_role:
        name: confluent.test
        tasks_from: check_property.yml
      vars:
        file_path: /etc/kafka/server.properties
        property: control.plane.listener.name
        expected_value: CONTROLLER

    - import_role:
        name: confluent.test
        tasks_from: check_property.yml
      vars:
        file_path: /etc/kafka/server.properties
        property: transaction.state.log.min.isr
        expected_value: "1"

    - name: Check Updated Service Description
      shell: systemctl status confluent-server
      register: systemctl_status
      failed_when: "'Custom Kafka description' not in systemctl_status.stdout_lines[0]"
      changed_when: false

    - name: Check Control Plane Listener Property
      import_role:
        name: confluent.test
        tasks_from: check_property.yml
      vars:
        file_path: /etc/kafka/server.properties
        property: listener.name.controller.sasl.enabled.mechanisms
        expected_value: PLAIN

    - import_role:
        name: confluent.test
        tasks_from: check_property.yml
      vars:
        file_path: /etc/kafka/log4j.properties
        property: log4j.rootLogger
        expected_value: "INFO, kafkaAppender"


- name: Verify - schema_registry
  hosts: schema_registry
  gather_facts: false
  tasks:
    - import_role:
        name: confluent.test
        tasks_from: check_property.yml
      vars:
        file_path: /etc/schema-registry/schema-registry.properties
        property: kafkastore.security.protocol
        expected_value: SASL_PLAINTEXT

    - name: Check Original Service Description
      shell: systemctl status confluent-schema-registry
      register: systemctl_status
      failed_when: "'RESTful Avro schema registry for Apache Kafka' not in systemctl_status.stdout_lines[0]"
      changed_when: false

    - import_role:
        name: confluent.test
        tasks_from: check_property.yml
      vars:
        file_path: /etc/schema-registry/log4j.properties
        property: log4j.rootLogger
        expected_value: "INFO, file"

- name: Verify - kafka_rest
  hosts: kafka_rest
  gather_facts: false
  tasks:
    - import_role:
        name: confluent.test
        tasks_from: check_property.yml
      vars:
        file_path: /etc/kafka-rest/kafka-rest.properties
        property: client.security.protocol
        expected_value: SASL_PLAINTEXT

    - name: Check Updated Service Description
      shell: systemctl status confluent-kafka-rest
      register: systemctl_status
      failed_when: "'Custom Rest Proxy description' not in systemctl_status.stdout_lines[0]"
      changed_when: false

    - import_role:
        name: confluent.test
        tasks_from: check_property.yml
      vars:
        file_path: /etc/kafka-rest/log4j.properties
        property: log4j.rootLogger
        expected_value: "INFO, file"

- name: Verify - kafka_connect
  hosts: kafka_connect
  gather_facts: false
  tasks:
    - import_role:
        name: confluent.test
        tasks_from: check_property.yml
      vars:
        file_path: /etc/kafka/connect-distributed.properties
        property: security.protocol
        expected_value: SASL_PLAINTEXT

    - import_role:
        name: confluent.test
        tasks_from: check_property.yml
      vars:
        file_path: /etc/kafka/connect-distributed.properties
        property: producer.sasl.jaas.config
        expected_value: 'org.apache.kafka.common.security.plain.PlainLoginModule required username="kafka_connect" password="kafka_connect-secret";'

    - name: Check Updated Service Description
      shell: systemctl status confluent-kafka-connect
      register: systemctl_status
      failed_when: "'Custom Connect description' not in systemctl_status.stdout_lines[0]"
      changed_when: false

    - name: Get Connectors on connect cluster1
      uri:
        url: "http://kafka-connect1:8083/connectors"
        status_code: 200
        validate_certs: false
      register: connectors

    - name: Assert Connector Created
      assert:
        that:
          - connectors.json[0] == "sample-connector-1"
        fail_msg: "Connector not created"
        quiet: true

    - import_role:
        name: confluent.test
        tasks_from: check_property.yml
      vars:
        file_path: /etc/kafka/connect-log4j.properties
        property: log4j.rootLogger
        expected_value: "INFO, connectAppender"

- name: Verify - ksql
  hosts: ksql
  gather_facts: false
  tasks:
    - import_role:
        name: confluent.test
        tasks_from: check_property.yml
      vars:
        file_path: /etc/ksqldb/ksql-server.properties
        property: security.protocol
        expected_value: SASL_PLAINTEXT

    - name: Check Updated Service Description
      shell: systemctl status confluent-ksqldb
      register: systemctl_status
      failed_when: "'Custom KSQLDB description' not in systemctl_status.stdout_lines[0]"
      changed_when: false

    - import_role:
        name: confluent.test
        tasks_from: check_property.yml
      vars:
        file_path: /etc/ksqldb/ksqldb-log4j.properties
        property: log4j.rootLogger
        expected_value: "INFO, main"
- name: Verify - control_center
  hosts: control_center
  gather_facts: false
  tasks:
    - import_role:
        name: confluent.test
        tasks_from: check_property.yml
      vars:
        file_path: /etc/confluent-control-center/control-center-production.properties
        property: confluent.controlcenter.streams.security.protocol
        expected_value: SASL_PLAINTEXT

    - name: Check Updated Service Description
      shell: systemctl status confluent-control-center
      register: systemctl_status
      failed_when: "'Custom C3 description' not in systemctl_status.stdout_lines[0]"
      changed_when: false

    - import_role:
        name: confluent.test
        tasks_from: check_property.yml
      vars:
        file_path: /etc/confluent-control-center/log4j-rolling.properties
        property: log4j.rootLogger
        expected_value: "INFO, stdout, main"
